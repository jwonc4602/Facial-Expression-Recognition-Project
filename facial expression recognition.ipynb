{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Dataset\n",
    "Got Dataset from _[Kaggle](https://www.kaggle.com/datasets/jonathanoheix/face-expression-recognition-dataset/discussion)_ check [images] folder for train/validation data sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Install libraries, packages and dataset\n",
    "import matplotlib for plotting and displaying images and import torch for using Pytorch for CNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:17.148853Z",
     "end_time": "2023-07-04T13:19:36.723221Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install timm\n",
    "!pip install --upgrade opencv-contrib-python\n",
    "!pip install -U git+https://github.com/albumentations-team/albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms as t"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:36.727927Z",
     "end_time": "2023-07-04T13:19:38.428105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Configurations\n",
    "Complete data loading as well as data augumentation. Transform train set images to get variety to enrich our training process with Compose, Flip, and Rotate. Also, converts image format to Tensor format with toTensor() for both train set and validation set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TRAIN_IMG_FOLDER_PATH = 'images/train'\n",
    "VALID_IMG_FOLDER_PATH = 'images/validation'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.428604Z",
     "end_time": "2023-07-04T13:19:38.430248Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_aug = t.Compose([\n",
    "    t.RandomHorizontalFlip(p=0.5),\n",
    "    t.RandomRotation(degrees=(-20, +20)),\n",
    "    t.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "valid_aug = t.Compose([\n",
    "    t.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.431931Z",
     "end_time": "2023-07-04T13:19:38.433330Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = ImageFolder(TRAIN_IMG_FOLDER_PATH, transform = train_aug)\n",
    "valid_set = ImageFolder(VALID_IMG_FOLDER_PATH, transform = valid_aug)\n",
    "\n",
    "print(f\"Total no. of examples in train set : {len(train_set)}\")\n",
    "print(f\"Total no. of examples in valid set : {len(valid_set)}\")\n",
    "\n",
    "print(train_set.class_to_idx)\n",
    "\n",
    "# Printing random example to checking step\n",
    "def print_random_img(train_set):\n",
    "    random.seed(299)\n",
    "    rand_idx = random.random()\n",
    "    image, label = train_set[int(rand_idx * len(train_set))]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    for idx, emotion in enumerate(train_set.class_to_idx.keys()):\n",
    "      if idx == label:\n",
    "        label = emotion\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "\n",
    "print_random_img(train_set=train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.436409Z",
     "end_time": "2023-07-04T13:19:38.674490Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "LR = 0.001  # Learning rate to be used during training\n",
    "BATCH_SIZE = 32  # The number of images to take during each training iteration\n",
    "EPOCHS = 50  # Determines the amount of training\n",
    "DEVICE='cpu'  # Enables you to perform compute-intensive operations faster by parallelizing tasks across GPUs\n",
    "MODEL_NAME='efficientnet_b0'  # A CNN model that is pre-trained on more than a million images from the ImageNet database\n",
    "\n",
    "# We will use DataLoader to load 32 images at a time to our CNN training model\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size  = BATCH_SIZE)\n",
    "\n",
    "# Analyzing one batch\n",
    "for images, labels in train_loader:\n",
    "    break\n",
    "\n",
    "print(f\"One image batch shape : {images.shape}\")\n",
    "print(f\"One label batch shape : {labels.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.673598Z",
     "end_time": "2023-07-04T13:19:38.839352Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Creating Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timm\n",
    "from torch import nn\n",
    "\n",
    "class FaceModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(FaceModel, self).__init__()\n",
    "\n",
    "    # Creating a NN model\n",
    "    self.eff_net = timm.create_model('efficientnet_b0', pretrained = True, num_classes = 7)\n",
    "\n",
    "  def forward(self, images, labels = None):\n",
    "    logits = self.eff_net(images)\n",
    "\n",
    "    if labels is not None:\n",
    "      loss = nn.CrossEntropyLoss()(logits, labels)  # Calculates the loss\n",
    "      return logits, loss\n",
    "\n",
    "    return logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.700010Z",
     "end_time": "2023-07-04T13:19:38.985376Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = FaceModel()\n",
    "model.to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:38.974854Z",
     "end_time": "2023-07-04T13:19:39.574105Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Create Train and Eval Function\n",
    "Optimizers are used to improve the model's accuracy with each iteration. Logits are the raw predictions (outputs) of our model. Loss quantifies how bad the model predicts (how far from the actual). With this information, we improve the model's accuracy. Also, we still get the logits and loss to calculate the model's performance, but we are not attempting to improve the model's accuracy here."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:39.568181Z",
     "end_time": "2023-07-04T13:19:39.574308Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def multiclass_accuracy(y_pred, y_true):\n",
    "  \"\"\"Creating a tensor (like an array) that compares predicted value with\n",
    "  actual value (assigning 1 if accurate, 0 if not),\n",
    "  then returning the mean value as accuracy\n",
    "  \"\"\"\n",
    "  top_p, top_class = y_pred.topk(1,dim=1)\n",
    "  equals = top_class == y_true.view(*top_class.shape)\n",
    "  return torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "def train_fn(model, dataloader, optimizer, current_epo):\n",
    "  \"\"\"Training function that trains the model, with the given optimizer, using\n",
    "  the given dataloader. During the training, it also calculates model's\n",
    "  total loss and total accuracy on training set, and returns these values.\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "  total_loss = 0.0\n",
    "  total_acc = 0.0\n",
    "  tk = tqdm(dataloader, desc = 'EPOCH' + \"[TRAIN]\" + str(current_epo + 1) + \"/\" +str(EPOCHS))\n",
    "\n",
    "  for t, data in enumerate(tk):\n",
    "    images, labels = data\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    logits, loss = model(images, labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_acc += multiclass_accuracy(logits, labels)\n",
    "    tk.set_postfix({'loss': '%6f' %float(total_loss/(t+1)), 'acc': '%6f' %float(total_acc / (t+1))})\n",
    "\n",
    "  return total_loss / len(dataloader), total_acc / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:39.574000Z",
     "end_time": "2023-07-04T13:19:39.575833Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def eval_fn(model, dataloader, current_epo):\n",
    "  \"\"\"Evaluation function that validates the model, with the given optimizer, using\n",
    "  the given dataloader. During the evaluation, it also calculates model's\n",
    "  total loss and total accuracy on validation set, and returns these values.\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  total_loss = 0.0\n",
    "  total_acc = 0.0\n",
    "  tk = tqdm(dataloader, desc = 'EPOCH' + \"[VALID]\" + str(current_epo + 1) + \"/\" +str(EPOCHS))\n",
    "\n",
    "  for t, data in enumerate(tk):\n",
    "    images, labels = data\n",
    "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "    logits, loss = model(images, labels)\n",
    "\n",
    "    total_loss += loss.item()\n",
    "    total_acc += multiclass_accuracy(logits, labels)\n",
    "    tk.set_postfix({'loss': '%6f' %float(total_loss/(t+1)), 'acc': '%6f' %float(total_acc / (t+1))})\n",
    "\n",
    "  return total_loss / len(dataloader), total_acc / len(dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-04T13:19:39.578514Z",
     "end_time": "2023-07-04T13:19:39.579912Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this section, we implement the Adam algorithm and Stochastic Optimization to create the training loop. We also keep track of the best validation loss in order to continually update it. The number of epochs is set to 50, so the training loop iterates for a total of 50 times. With each iteration, we expect both the training loss and validation loss to decrease gradually as our model becomes more accurate.\n",
    "\n",
    "We specifically focus on minimizing the validation loss rather than the training loss because our ultimate goal is to have a model that performs well in real-life scenarios beyond just our training data. While accuracy can be subjectively biased, measuring how close we are to reality through minimizing loss provides us with a better understanding of truthfulness."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "best_valid_loss = np.Inf\n",
    "\n",
    "for i in range (EPOCHS):\n",
    "  train_loss, train_acc = train_fn(model, train_loader, optimizer, i)\n",
    "  valid_loss, valid_acc = eval_fn(model, valid_loader, i)\n",
    "\n",
    "  if valid_loss < best_valid_loss:\n",
    "    torch.save(model.state_dict(), \"best.weights.pt\")\n",
    "    print(\"SAVED-BEST-WEIGHTS\")\n",
    "    best_valid_loss = valid_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-08T13:02:32.152295Z",
     "end_time": "2023-06-08T18:14:18.152054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Data Visualization\n",
    "Drawing plots using Matplotlib about testing, training accuracy and testing, training loss for each Epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(EPOCHS,train_acc, label = \"Training Accuracy\")\n",
    "plt.plot(EPOCHS,valid_acc, label = \"Testing Accuracy\")\n",
    "plt.title(\"Testing Accuracy & Training Accuracy for each epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-06-15T10:37:53.336989Z",
     "end_time": "2023-06-15T10:37:53.347786Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(EPOCHS, train_loss, label = \"Training Loss\")\n",
    "plt.plot(EPOCHS, valid_loss, label = \"Test Loss\")\n",
    "plt.title(\"Testing Loss & Training Loss for each epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def view_classify(img, ps):\n",
    "\n",
    "    classes = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "    ps = ps.data.cpu().numpy().squeeze()\n",
    "    img = img.numpy().transpose(1,2,0)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(5,9), ncols=2)\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(classes, ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(classes)\n",
    "    ax2.set_yticklabels(classes)\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
